{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22407, 39)\n",
      "Index(['decile1b', 'decile3', 'ID', 'decile1', 'sex', 'race', 'cluster',\n",
      "       'lsat', 'ugpa', 'zfygpa', 'DOB_yr', 'grad', 'zgpa', 'bar1', 'bar1_yr',\n",
      "       'bar2', 'bar2_yr', 'fulltime', 'fam_inc', 'age', 'gender', 'parttime',\n",
      "       'male', 'race1', 'race2', 'Dropout', 'other', 'asian', 'black', 'hisp',\n",
      "       'pass_bar', 'bar', 'bar_passed', 'tier', 'index6040', 'indxgrp',\n",
      "       'indxgrp2', 'dnn_bar_pass_prediction', 'gpa'],\n",
      "      dtype='object')\n",
      "decile1b                   1604\n",
      "decile3                    1604\n",
      "ID                            0\n",
      "decile1                    1092\n",
      "sex                           5\n",
      "race                         16\n",
      "cluster                      96\n",
      "lsat                          0\n",
      "ugpa                          0\n",
      "zfygpa                      984\n",
      "DOB_yr                       50\n",
      "grad                          3\n",
      "zgpa                       1289\n",
      "bar1                          0\n",
      "bar1_yr                      39\n",
      "bar2                          0\n",
      "bar2_yr                      40\n",
      "fulltime                     34\n",
      "fam_inc                     289\n",
      "age                          89\n",
      "gender                        5\n",
      "parttime                     34\n",
      "male                          5\n",
      "race1                        16\n",
      "race2                        16\n",
      "Dropout                       0\n",
      "other                         0\n",
      "asian                         0\n",
      "black                         0\n",
      "hisp                          0\n",
      "pass_bar                      0\n",
      "bar                           0\n",
      "bar_passed                    0\n",
      "tier                         96\n",
      "index6040                     0\n",
      "indxgrp                       0\n",
      "indxgrp2                      0\n",
      "dnn_bar_pass_prediction       0\n",
      "gpa                           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decile1b</th>\n",
       "      <th>decile3</th>\n",
       "      <th>ID</th>\n",
       "      <th>decile1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "      <th>...</th>\n",
       "      <th>hisp</th>\n",
       "      <th>pass_bar</th>\n",
       "      <th>bar</th>\n",
       "      <th>bar_passed</th>\n",
       "      <th>tier</th>\n",
       "      <th>index6040</th>\n",
       "      <th>indxgrp</th>\n",
       "      <th>indxgrp2</th>\n",
       "      <th>dnn_bar_pass_prediction</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>886.842082</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>649.999987</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>760.526298</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>807.894717</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>949.999974</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   decile1b  decile3  ID  decile1  sex  race  cluster  lsat  ugpa  zfygpa  \\\n",
       "0      10.0     10.0   2     10.0  1.0   7.0      1.0  44.0   3.5    1.33   \n",
       "1       5.0      4.0   3      5.0  1.0   7.0      2.0  29.0   3.5   -0.11   \n",
       "2       3.0      2.0  36      3.0  2.0   7.0      3.0  36.0   3.5   -0.64   \n",
       "3       7.0      4.0  52      7.0  2.0   7.0      3.0  39.0   3.5    0.34   \n",
       "4       9.0      8.0  55      9.0  2.0   7.0      4.0  48.0   3.5    1.02   \n",
       "\n",
       "   ...  hisp pass_bar                bar bar_passed  tier   index6040  \\\n",
       "0  ...     0        1  a Passed 1st time       True   4.0  886.842082   \n",
       "1  ...     0        1  a Passed 1st time       True   2.0  649.999987   \n",
       "2  ...     0        1  a Passed 1st time       True   3.0  760.526298   \n",
       "3  ...     0        1  a Passed 1st time       True   3.0  807.894717   \n",
       "4  ...     0        1  a Passed 1st time       True   5.0  949.999974   \n",
       "\n",
       "     indxgrp   indxgrp2  dnn_bar_pass_prediction  gpa  \n",
       "0     g 700+     i 820+                 0.979804  3.5  \n",
       "1  f 640-700  f 640-700                 0.979804  3.5  \n",
       "2     g 700+  h 760-820                 0.979804  3.5  \n",
       "3     g 700+  h 760-820                 0.979804  3.5  \n",
       "4     g 700+     i 820+                 0.979804  3.5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "admissions_df = pd.read_csv('../datasets/data/bar_pass_prediction.csv', index_col=False)\n",
    "print(admissions_df.shape)\n",
    "print(admissions_df.columns)\n",
    "print(admissions_df.isnull().sum())\n",
    "display(admissions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data cleaning\n",
    "\n",
    "A subset of the [Law School Admission Bar*](https://www.kaggle.com/datasets/danofer/law-school-admissions-bar-passage) dataset is used as a demo. Synthetic data will be generated for the following columns: \n",
    "\n",
    "- sex: student gender, i.e. 1 (male), 2 (female)\n",
    "- race1: race, i.e. asian, black, hispanic, white, other\n",
    "- ugpa: The student's undergraduate GPA, continous variable;\n",
    "- bar: Ground truth label indicating whether or not the student passed the bar, i.e. passed 1st time, passed 2nd time, failed, non-graduated\n",
    "\n",
    "The CART method will be used  evaluate the distribution and correlation differences between the real and synthetic data.\n",
    "\n",
    "*The original paper can be found [here](https://files.eric.ed.gov/fulltext/ED469370.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_sub = admissions_df[['sex', 'race1', 'ugpa', 'bar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22387, 4)\n",
      "sex      0\n",
      "race1    0\n",
      "ugpa     0\n",
      "bar      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows with missing values\n",
    "real_data = admissions_sub.dropna()\n",
    "print(real_data.shape)\n",
    "print(real_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race1</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>3.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>3.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>white</td>\n",
       "      <td>3.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>white</td>\n",
       "      <td>3.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>white</td>\n",
       "      <td>3.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22402</th>\n",
       "      <td>2.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22403</th>\n",
       "      <td>2.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>2.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.8</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22405</th>\n",
       "      <td>2.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1.5</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22406</th>\n",
       "      <td>2.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1.6</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22387 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  race1  ugpa                bar\n",
       "0      1.0  white   3.5  a Passed 1st time\n",
       "1      1.0  white   3.5  a Passed 1st time\n",
       "2      2.0  white   3.5  a Passed 1st time\n",
       "3      2.0  white   3.5  a Passed 1st time\n",
       "4      2.0  white   3.5  a Passed 1st time\n",
       "...    ...    ...   ...                ...\n",
       "22402  2.0  black   1.8           c Failed\n",
       "22403  2.0  black   1.8           c Failed\n",
       "22404  2.0  black   1.8  a Passed 1st time\n",
       "22405  2.0  white   1.5  a Passed 1st time\n",
       "22406  2.0  white   1.6  a Passed 1st time\n",
       "\n",
       "[22387 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# classes\n",
    "from synthpop.validator import Validator\n",
    "from synthpop.processor import Processor\n",
    "# global variables\n",
    "from synthpop import NUM_COLS_DTYPES\n",
    "from synthpop.processor import NAN_KEY\n",
    "from synthpop.method import CART_METHOD, METHODS_MAP, NA_METHODS\n",
    "\n",
    "\n",
    "class Synthpop:\n",
    "    def __init__(self,\n",
    "                 method=None,\n",
    "                 visit_sequence=None,\n",
    "                 # predictor_matrix=None,\n",
    "                 proper=False,\n",
    "                 cont_na=None,\n",
    "                 smoothing=False,\n",
    "                 default_method=CART_METHOD,\n",
    "                 numtocat=None,\n",
    "                 catgroups=None,\n",
    "                 seed=None):\n",
    "        # initialise the validator and processor\n",
    "        self.validator = Validator(self)\n",
    "        self.processor = Processor(self)\n",
    "\n",
    "        # initialise arguments\n",
    "        self.method = method\n",
    "        self.visit_sequence = visit_sequence\n",
    "        self.predictor_matrix = None\n",
    "        self.proper = proper\n",
    "        self.cont_na = cont_na\n",
    "        self.smoothing = smoothing\n",
    "        self.default_method = default_method\n",
    "        self.numtocat = numtocat\n",
    "        self.catgroups = catgroups\n",
    "        self.seed = seed\n",
    "\n",
    "        # check init\n",
    "        self.validator.check_init()\n",
    "\n",
    "    def fit(self, df, dtypes=None):\n",
    "        # TODO check df and check/EXTRACT dtypes\n",
    "        # - all column names of df are unique\n",
    "        # - all columns data of df are consistent\n",
    "        # - all dtypes of df are correct ('int', 'float', 'datetime', 'category', 'bool'; no object)\n",
    "        # - can map dtypes (if given) correctly to df\n",
    "        # should create map col: dtype (self.df_dtypes)\n",
    "\n",
    "        self.df_columns = df.columns.tolist()\n",
    "        self.n_df_rows, self.n_df_columns = np.shape(df)\n",
    "        self.df_dtypes = dtypes\n",
    "\n",
    "        # check processor\n",
    "        self.validator.check_processor()\n",
    "        # preprocess\n",
    "        processed_df = self.processor.preprocess(df, self.df_dtypes)\n",
    "        self.processed_df_columns = processed_df.columns.tolist()\n",
    "        self.n_processed_df_columns = len(self.processed_df_columns)\n",
    "\n",
    "        # check fit\n",
    "        self.validator.check_fit()\n",
    "        # fit\n",
    "        self._fit(processed_df)\n",
    "\n",
    "    def _fit(self, df):\n",
    "        self.saved_methods = {}\n",
    "\n",
    "        # train\n",
    "        self.predictor_matrix_columns = self.predictor_matrix.columns.to_numpy()\n",
    "        for col, visit_step in self.visit_sequence.sort_values().items():\n",
    "            print('train_{}'.format(col))\n",
    "\n",
    "            # initialise the method\n",
    "            col_method = METHODS_MAP[self.method[col]](dtype=self.df_dtypes[col], smoothing=self.smoothing[col], proper=self.proper, random_state=self.seed)\n",
    "            # fit the method\n",
    "            col_predictors = self.predictor_matrix_columns[self.predictor_matrix.loc[col].to_numpy() == 1]\n",
    "            col_method.fit(X_df=df[col_predictors], y_df=df[col])\n",
    "            # save the method\n",
    "            self.saved_methods[col] = col_method\n",
    "\n",
    "    def generate(self, k=None):\n",
    "        self.k = k\n",
    "\n",
    "        # check generate\n",
    "        self.validator.check_generate()\n",
    "        # generate\n",
    "        synth_df = self._generate()\n",
    "        # postprocess\n",
    "        processed_synth_df = self.processor.postprocess(synth_df)\n",
    "\n",
    "        return processed_synth_df\n",
    "\n",
    "    def _generate(self):\n",
    "        synth_df = pd.DataFrame(data=np.zeros([self.k, len(self.visit_sequence)]), columns=self.visit_sequence.index)\n",
    "\n",
    "        for col, visit_step in self.visit_sequence.sort_values().items():\n",
    "            print('generate_{}'.format(col))\n",
    "\n",
    "            # reload the method\n",
    "            col_method = self.saved_methods[col]\n",
    "            # predict with the method\n",
    "            col_predictors = self.predictor_matrix_columns[self.predictor_matrix.loc[col].to_numpy() == 1]\n",
    "            synth_df[col] = col_method.predict(synth_df[col_predictors])\n",
    "\n",
    "            # change all missing values to 0\n",
    "            if col in self.processor.processing_dict[NAN_KEY] and self.df_dtypes[col] in NUM_COLS_DTYPES and self.method[col] in NA_METHODS:\n",
    "                nan_indices = synth_df[self.processor.processing_dict[NAN_KEY][col]['col_nan_name']] != 0\n",
    "                synth_df.loc[nan_indices, col] = 0\n",
    "\n",
    "            # map dtype to original dtype (only excpetion if column is full of NaNs)\n",
    "            if synth_df[col].notna().any():\n",
    "                synth_df[col] = synth_df[col].astype(self.df_dtypes[col])\n",
    "\n",
    "        return synth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# global variables\n",
    "from synthpop import NUM_COLS_DTYPES\n",
    "from synthpop.method import EMPTY_METHOD, SAMPLE_METHOD\n",
    "from synthpop.method import DEFAULT_METHODS_MAP, INIT_METHODS_MAP, CONT_TO_CAT_METHODS_MAP\n",
    "from synthpop.method import ALL_METHODS, INIT_METHODS, DEFAULT_METHODS, NA_METHODS\n",
    "from synthpop.processor import NAN_KEY\n",
    "\n",
    "\n",
    "INIT_STEP = 'init'\n",
    "PROCESSOR_STEP = 'processor'\n",
    "FIT_STEP = 'fit'\n",
    "GENERATE_STEP = 'generate'\n",
    "\n",
    "NONE_TYPE = type(None)\n",
    "\n",
    "DENSITY = 'density'\n",
    "\n",
    "\n",
    "class Validator:\n",
    "    def __init__(self, spop):\n",
    "        self.spop = spop\n",
    "        self.attributes_types = {'method': (NONE_TYPE, str, list),\n",
    "                                 'visit_sequence': (NONE_TYPE, np.ndarray, list),\n",
    "                                 # 'predictor_matrix': (NONE_TYPE,),\n",
    "                                 'proper': (bool,),\n",
    "                                 'cont_na': (NONE_TYPE, dict),\n",
    "                                 'smoothing': (bool, str, dict),\n",
    "                                 'default_method': (str,),\n",
    "                                 'numtocat': (NONE_TYPE, list),\n",
    "                                 'catgroups': (NONE_TYPE, int, dict),\n",
    "                                 'seed': (NONE_TYPE, int),\n",
    "                                 'k': (NONE_TYPE, int)}\n",
    "\n",
    "    def check_init(self):\n",
    "        step = INIT_STEP\n",
    "\n",
    "        self.default_method_validator(step=step)\n",
    "        self.method_validator(step=step)\n",
    "        self.visit_sequence_validator(step=step)\n",
    "        # self.predictor_matrix_validator(step=step)\n",
    "        self.proper_validator(step=step)\n",
    "        self.cont_na_validator(step=step)\n",
    "        self.smoothing_validator(step=step)\n",
    "        self.numtocat_validator(step=step)\n",
    "        self.catgroups_validator(step=step)\n",
    "        self.seed_validator(step=step)\n",
    "\n",
    "    def check_processor(self):\n",
    "        step = PROCESSOR_STEP\n",
    "\n",
    "        self.visit_sequence_validator(step=step)\n",
    "        self.method_validator(step=step)\n",
    "        self.predictor_matrix_validator(step=step)\n",
    "        self.smoothing_validator(step=step)\n",
    "\n",
    "        self.cont_na_validator(step=step)\n",
    "        self.numtocat_validator(step=step)\n",
    "        self.catgroups_validator(step=step)\n",
    "\n",
    "    def check_fit(self):\n",
    "        step = FIT_STEP\n",
    "\n",
    "        self.method_validator(step=step)\n",
    "        self.visit_sequence_validator(step=step)\n",
    "        self.predictor_matrix_validator(step=step)\n",
    "        self.smoothing_validator(step=step)\n",
    "\n",
    "    def check_generate(self):\n",
    "        step = GENERATE_STEP\n",
    "\n",
    "        self.k_validator(step=step)\n",
    "\n",
    "    def check_valid_type(self, attribute_name, return_type=False):\n",
    "        attribute_type = getattr(self.spop, attribute_name)\n",
    "        expected_types = self.attributes_types[attribute_name]\n",
    "        assert isinstance(attribute_type, expected_types)\n",
    "\n",
    "        if return_type:\n",
    "            return attribute_type\n",
    "\n",
    "    def method_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate method type is allowed\n",
    "            method_type = self.check_valid_type('method', return_type=True)\n",
    "\n",
    "            if isinstance(method_type, str):\n",
    "                # if method type is str\n",
    "                # validate method is in allowed init methods\n",
    "                assert self.spop.method in INIT_METHODS\n",
    "\n",
    "            elif isinstance(method_type, list):\n",
    "                # if method type is list\n",
    "                # validate all methods are allowed\n",
    "                assert all(m in ALL_METHODS for m in self.spop.method)\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            first_visited_col = self.spop.visit_sequence.index[self.spop.visit_sequence == 0].values[0]\n",
    "\n",
    "            if self.spop.method is None:\n",
    "                # if method is not specified\n",
    "                # for each column set method to default method according to its dtype (method for first visited column is sample_method)\n",
    "                self.spop.method = [DEFAULT_METHODS_MAP[self.spop.default_method][self.spop.df_dtypes[col]] if col != first_visited_col else SAMPLE_METHOD\n",
    "                                    for col in self.spop.df_columns]\n",
    "\n",
    "            elif isinstance(self.spop.method, str):\n",
    "                # if method type is str\n",
    "                # for each column set method to the corresponding allowed method according to its dtype (method for first visited column is sample_method)\n",
    "                self.spop.method = [INIT_METHODS_MAP[self.spop.method][self.spop.df_dtypes[col]] if col != first_visited_col else SAMPLE_METHOD\n",
    "                                    for col in self.spop.df_columns]\n",
    "\n",
    "            else:\n",
    "                # validate method for first visited column with non empty method is sample_method\n",
    "                for col, visit_order in self.spop.visit_sequence.sort_values().items():\n",
    "                    col_method = self.spop.method[self.spop.df_columns.index(col)]\n",
    "                    if col_method != EMPTY_METHOD:\n",
    "                        assert col_method == SAMPLE_METHOD\n",
    "                        break\n",
    "                # assert all(self.spop.method[i] == SAMPLE_METHOD for i, col in enumerate(self.spop.df_columns) if col == first_visited_col)\n",
    "\n",
    "            # validate all columns have specified methods\n",
    "            assert len(self.spop.method) == self.spop.n_df_columns\n",
    "            self.spop.method = pd.Series(self.spop.method, index=self.spop.df_columns)\n",
    "\n",
    "        if step == FIT_STEP:\n",
    "            for col in self.spop.method.index:\n",
    "                if col in self.spop.numtocat:\n",
    "                    self.spop.method[col] = CONT_TO_CAT_METHODS_MAP[self.spop.method[col]]\n",
    "\n",
    "                elif col in self.spop.processor.processing_dict[NAN_KEY] and self.spop.df_dtypes[col] in NUM_COLS_DTYPES and self.spop.method[col] in NA_METHODS:\n",
    "                    # TODO put in a function\n",
    "                    nan_col_index = self.spop.method.index.get_loc(col)\n",
    "                    index_list = self.spop.method.index.tolist()\n",
    "                    index_list.insert(nan_col_index, self.spop.processed_df_columns[nan_col_index])\n",
    "                    self.spop.method = self.spop.method.reindex(index_list, fill_value=CONT_TO_CAT_METHODS_MAP[self.spop.method[col]])\n",
    "\n",
    "    def visit_sequence_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate visit_sequence type is allowed\n",
    "            visit_sequence_type = self.check_valid_type('visit_sequence', return_type=True)\n",
    "\n",
    "            if isinstance(visit_sequence_type, np.ndarray):\n",
    "                # if visit_sequence type is numpy array\n",
    "                # transform visit_sequence into a list\n",
    "                self.spop.visit_sequence = [col.item() for col in self.spop.visit_sequence]\n",
    "                visit_sequence_type = list\n",
    "\n",
    "            if isinstance(visit_sequence_type, list):\n",
    "                # if visit_sequence type is list\n",
    "                # validate all visits are unique\n",
    "                assert len(set(self.spop.visit_sequence)) == len(self.spop.visit_sequence)\n",
    "                # validate all visits are either type int or type str\n",
    "                assert all(isinstance(col, int) for col in self.spop.visit_sequence) or all(isinstance(col, str) for col in self.spop.visit_sequence)\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            if self.spop.visit_sequence is None:\n",
    "                # if visit_sequence is not specified\n",
    "                # visit all columns in a row\n",
    "                self.spop.visit_sequence = [col.item() for col in np.arange(self.spop.n_df_columns)]\n",
    "\n",
    "            if isinstance(self.spop.visit_sequence[0], int):\n",
    "                # if visit_sequence is list of column indices\n",
    "                # validate every index in visit_sequence is a valid column index\n",
    "                assert set(self.spop.visit_sequence).issubset(set(np.arange(self.spop.n_df_columns)))\n",
    "                # transform visit_sequence into a list of column names\n",
    "                self.spop.visit_sequence = [self.spop.df_columns[i] for i in self.spop.visit_sequence]\n",
    "            else:\n",
    "                # validate every column name in visit_sequence is a valid column name\n",
    "                assert set(self.spop.visit_sequence).issubset(set(self.spop.df_columns))\n",
    "\n",
    "            self.spop.visited_columns = [col for col in self.spop.df_columns if col in self.spop.visit_sequence]\n",
    "            self.spop.visit_sequence = pd.Series([self.spop.visit_sequence.index(col) for col in self.spop.visited_columns], index=self.spop.visited_columns)\n",
    "\n",
    "        if step == FIT_STEP:\n",
    "            for col in self.spop.visit_sequence.index:\n",
    "                if col in self.spop.processor.processing_dict[NAN_KEY] and self.spop.df_dtypes[col] in NUM_COLS_DTYPES and self.spop.method[col] in NA_METHODS:\n",
    "                    visit_step = self.spop.visit_sequence[col]\n",
    "                    self.spop.visit_sequence.loc[self.spop.visit_sequence >= visit_step] += 1\n",
    "\n",
    "                    nan_col_index = self.spop.visit_sequence.index.get_loc(col)\n",
    "                    index_list = self.spop.visit_sequence.index.tolist()\n",
    "                    index_list.insert(nan_col_index, self.spop.processed_df_columns[nan_col_index])\n",
    "                    self.spop.visit_sequence = self.spop.visit_sequence.reindex(index_list, fill_value=visit_step)\n",
    "\n",
    "    def predictor_matrix_validator(self, step=None):\n",
    "        # if step == INIT_STEP:\n",
    "        #     # validate predictor_matrix type is allowed\n",
    "        #     self.check_valid_type('predictor_matrix')\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            # build predictor_matrix so all previously visited columns are used for the prediction of the currently visited\n",
    "            self.spop.predictor_matrix = np.zeros([len(self.spop.visit_sequence), len(self.spop.visit_sequence)], dtype=int)\n",
    "            self.spop.predictor_matrix = pd.DataFrame(self.spop.predictor_matrix, index=self.spop.visit_sequence.index, columns=self.spop.visit_sequence.index)\n",
    "            visited_columns = []\n",
    "            for col, _ in self.spop.visit_sequence.sort_values().items():\n",
    "                self.spop.predictor_matrix.loc[col, visited_columns] = 1\n",
    "                visited_columns.append(col)\n",
    "\n",
    "        if step == FIT_STEP:\n",
    "            for col in self.spop.predictor_matrix:\n",
    "                if col in self.spop.processor.processing_dict[NAN_KEY] and self.spop.df_dtypes[col] in NUM_COLS_DTYPES and self.spop.method[col] in NA_METHODS:\n",
    "                    nan_col_index = self.spop.predictor_matrix.columns.get_loc(col)\n",
    "                    self.spop.predictor_matrix.insert(nan_col_index, self.spop.processed_df_columns[nan_col_index], self.spop.predictor_matrix[col])\n",
    "\n",
    "                    index_list = self.spop.predictor_matrix.index.tolist()\n",
    "                    index_list.insert(nan_col_index, self.spop.processed_df_columns[nan_col_index])\n",
    "                    self.spop.predictor_matrix = self.spop.predictor_matrix.reindex(index_list, fill_value=0)\n",
    "                    self.spop.predictor_matrix.loc[self.spop.processed_df_columns[nan_col_index]] = self.spop.predictor_matrix.loc[col]\n",
    "\n",
    "                    self.spop.predictor_matrix.loc[col, self.spop.processed_df_columns[nan_col_index]] = 1\n",
    "\n",
    "    def proper_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate proper type is allowed\n",
    "            self.check_valid_type('proper')\n",
    "\n",
    "    def cont_na_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate cont_na type is allowed\n",
    "            self.check_valid_type('cont_na')\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            if self.spop.cont_na is None:\n",
    "                self.spop.cont_na = {}\n",
    "            else:\n",
    "                # validate columns in cont_na are valid columns\n",
    "                assert all(col in self.spop.df_columns for col in self.spop.cont_na)\n",
    "                # assert all(col in self.spop.visited_columns for col in self.spop.cont_na)\n",
    "                # validate the type of columns in cont_na are valid types\n",
    "                assert all(self.spop.df_dtypes[col] in NUM_COLS_DTYPES for col in self.spop.cont_na)\n",
    "                self.spop.cont_na = {col: col_cont_na for col, col_cont_na in self.spop.cont_na.items() if self.spop.method[col] in NA_METHODS}\n",
    "\n",
    "    def smoothing_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate smoothing type is allowed\n",
    "            self.check_valid_type('smoothing')\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            if self.spop.smoothing is False:\n",
    "                self.spop.smoothing = {col: False for col in self.spop.df_columns}\n",
    "            elif isinstance(self.spop.smoothing, str):\n",
    "                # if smoothing type is str\n",
    "                # validate smoothing is 'density'\n",
    "                assert self.spop.smoothing == DENSITY\n",
    "                self.spop.smoothing = {col: self.spop.df_dtypes[col] in NUM_COLS_DTYPES for col in self.spop.df_columns}\n",
    "            else:\n",
    "                # validate smoothing is 'denisty' for some/all numerical columns and False for all other columns\n",
    "                assert all((smoothing_method == DENSITY and self.spop.df_dtypes[col] in NUM_COLS_DTYPES) or smoothing_method is False\n",
    "                           for col, smoothing_method in self.spop.smoothing.items())\n",
    "                self.spop.smoothing = {col: (self. spop.smoothing.get(col, False) == DENSITY and self.spop.df_dtypes[col] in NUM_COLS_DTYPES) for col in self.spop.df_columns}\n",
    "\n",
    "        if step == FIT_STEP:\n",
    "            for col in self.spop.processed_df_columns:\n",
    "                if col in self.spop.numtocat:\n",
    "                    self.spop.smoothing[col] = False\n",
    "                elif col in self.spop.processor.processing_dict[NAN_KEY] and self.spop.df_dtypes[col] in NUM_COLS_DTYPES:\n",
    "                    self.spop.smoothing[self.spop.processor.processing_dict[NAN_KEY][col]['col_nan_name']] = False\n",
    "\n",
    "    def default_method_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate default_method type is allowed\n",
    "            self.check_valid_type('default_method')\n",
    "\n",
    "            # validate default_method is in allowed default methods\n",
    "            assert self.spop.default_method in DEFAULT_METHODS\n",
    "\n",
    "    def numtocat_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate numtocat type is allowed\n",
    "            self.check_valid_type('numtocat')\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            if self.spop.numtocat is None:\n",
    "                self.spop.numtocat = []\n",
    "            else:\n",
    "                # validate all columns in numtocat are valid columns\n",
    "                assert all(col in self.spop.df_columns for col in self.spop.numtocat)\n",
    "                # assert all(col in self.spop.visited_columns for col in self.spop.numtocat)\n",
    "                # validate all columns in numtocat are numerical columns\n",
    "                assert all(self.spop.df_dtypes[col] in NUM_COLS_DTYPES for col in self.spop.numtocat)\n",
    "\n",
    "    def catgroups_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate catgroups type is allowed\n",
    "            catgroups_type = self.check_valid_type('catgroups', return_type=True)\n",
    "\n",
    "            if isinstance(catgroups_type, int):\n",
    "                # if catgroups type is int\n",
    "                # validate catgroups is more than 1\n",
    "                assert self.spop.catgroups > 1\n",
    "\n",
    "            elif isinstance(catgroups_type, dict):\n",
    "                # if catgroups type is dict\n",
    "                # validate the keys in catgroups are the same as the columns in numtocat\n",
    "                assert set(self.spop.catgroups.keys()) == set(self.spop.numtocat)\n",
    "                # validate all values in catgroups are type int and more than 1\n",
    "                assert all((isinstance(col_groups, int) and col_groups > 1) for col_groups in self.spop.catgroups.values())\n",
    "\n",
    "        if step == PROCESSOR_STEP:\n",
    "            if self.spop.catgroups is None:\n",
    "                self.spop.catgroups = {col: 5 for col in self.spop.numtocat}\n",
    "            elif isinstance(self.spop.catgroups, int):\n",
    "                self.spop.catgroups = {col: self.spop.catgroups for col in self.spop.numtocat}\n",
    "\n",
    "    def seed_validator(self, step=None):\n",
    "        if step == INIT_STEP:\n",
    "            # validate seed type is allowed\n",
    "            self.check_valid_type('seed')\n",
    "\n",
    "    def k_validator(self, step=None):\n",
    "        if step == GENERATE_STEP:\n",
    "            # validate k type is allowed\n",
    "            self.check_valid_type('k')\n",
    "\n",
    "            if self.spop.k is None:\n",
    "                self.spop.k = self.spop.n_df_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data types are correctly set\n",
    "my_data_frame = real_data.copy()\n",
    "my_data_frame['sex'] = my_data_frame['sex'].astype('category')\n",
    "my_data_frame['race'] = my_data_frame['race'].astype('category')\n",
    "my_data_frame['gpa'] = my_data_frame['gpa'].astype('float')\n",
    "\n",
    "# Define the data types for each column\n",
    "dtypes = {\n",
    "\t'sex': 'category',\n",
    "\t'race': 'category',\n",
    "\t'gpa': 'float'\n",
    "}\n",
    "\n",
    "# Initialize Synthpop object with method 'cart'\n",
    "spop = Synthpop(method='cart')\n",
    "\n",
    "# Fit the Synthpop model\n",
    "# spop.fit(my_data_frame, dtypes=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sex\n",
      "train_race\n",
      "train_gpa\n"
     ]
    }
   ],
   "source": [
    "spop.fit(my_data_frame, dtypes=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_sex\n",
      "generate_race\n",
      "generate_gpa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex race  gpa\n",
       "0   1.0  7.0  3.6\n",
       "1   2.0  7.0  3.7\n",
       "2   2.0  7.0  3.5\n",
       "3   1.0  7.0  3.0\n",
       "4   2.0  7.0  3.1\n",
       "..  ...  ...  ...\n",
       "95  2.0  7.0  3.4\n",
       "96  1.0  3.0  3.3\n",
       "97  1.0  7.0  3.3\n",
       "98  1.0  7.0  3.4\n",
       "99  2.0  7.0  3.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spop.generate(k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
